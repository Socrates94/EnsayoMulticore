%!TEX root = main.tex
\section{Discusión}

\subsection{Comparación entre vectorizaciones}
A nivel de precisión algorítmica, todas las implementaciones procesaron correctamente la matriz de la imagen PGM, generando los gradientes y contornos esperados sin pérdida de fidelidad visual ni matemática. Sin embargo, el rendimiento dinámico expuso contrastes severos entre la teoría y la práctica del paralelismo a nivel de datos. 

Mientras que el compilador, en sus versiones Automática y Guiada (OpenMP), optó por un enfoque conservador al detectar latencias de memoria (manteniendo el rendimiento estancado por debajo del pico escalar de 9.49 GFLOPS), la versión Explícita (AVX2) forzó exitosamente el uso de las unidades vectoriales. No obstante, a pesar de que esta última versión maximizó el empaquetado en registros de 256 bits y disparó el rendimiento de las ALUs, el \textit{speedup} global empírico frente a la versión escalar fue estadísticamente nulo (oscilando entre $0.98\times$ y $1.00\times$).

\subsection{Interpretación de los resultados y Diagnóstico}
La discrepancia entre el alto procesamiento matemático alcanzado por las intrínsecas y la falta de aceleración en tiempo real se explica íntegramente a través del modelo Roofline. El cálculo del operador Sobel presenta una intensidad aritmética críticamente baja, perfilada en 0.069 FLOP/Byte. Por cada cálculo matemático simple ejecutado, el procesador está obligado a transportar grandes volúmenes de datos desde y hacia la memoria principal (lectura de operandos $G_x$ y $G_y$, y escritura del resultado de la magnitud).

Como consecuencia, los puntos de ejecución en las gráficas nunca logran escalar hacia los "techos" horizontales de capacidad computacional máxima. En su lugar, colisionan prematuramente contra las líneas diagonales que dictan el límite físico del hardware: el ancho de banda de la memoria DRAM (saturado a $\sim$31 GB/s). 

Este fenómeno provoca inanición de datos (\textit{data starvation}) en los registros SIMD; el procesador es capaz de calcular 8 píxeles simultáneamente en una fracción de ciclo de reloj, pero pasa la inmensa mayoría del tiempo inactivo, esperando a que el bus de memoria entregue el siguiente bloque de datos. Por lo tanto, se concluye categóricamente que el kernel evaluado es un algoritmo estrictamente \textit{Memory-Bound}. Para obtener mejoras tangibles de rendimiento en trabajos futuros, la estrategia deberá girar hacia técnicas que maximicen la localidad de datos (como \textit{loop tiling}) para explotar la memoria caché L1/L2, reduciendo el costoso tráfico hacia la RAM.