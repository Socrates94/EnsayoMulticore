%!TEX root = main.tex
\section{Conclusiones}

Este análisis experimental demuestra empíricamente que la optimización de código mediante vectorización explícita AVX2 es una herramienta computacional poderosa, pero su efectividad está estrictamente condicionada por la arquitectura de memoria del sistema. Se comprobó que, en kernels iterativos como el operador Sobel, el cuello de botella físico impide reflejar el poder matemático en un \textit{speedup} real, resultando en una aceleración estadísticamente nula ($\sim 1.0\times$).

El perfilado de hardware con Intel Advisor reveló que la limitante no es la falta de paralelismo: la versión explícita estimuló correctamente el hardware alcanzando 68.76 GFLOPS, superando por casi un factor de $7\times$ el límite teórico escalar. El verdadero muro arquitectónico es la bajísima intensidad aritmética del algoritmo (0.069 FLOP/Byte) frente al ancho de banda de la memoria principal. El bus de la tecnología DDR4 del equipo de pruebas alcanzó su límite físico de transferencia (saturándose a $\sim$29 GB/s), lo que provocó una severa inanición de datos en los registros de 256 bits.

En consecuencia, para obtener mejoras significativas de rendimiento en este tipo de procesamiento de imágenes masivo, no basta con acelerar las unidades aritmético-lógicas (ALUs) mediante instrucciones SIMD. Las futuras investigaciones deberán cambiar el enfoque hacia la reestructuración algorítmica, priorizando técnicas que incrementen la localidad de datos, como el bloqueo de ciclos (\textit{loop blocking} o \textit{tiling}). Esto permitirá maximizar la reutilización de píxeles en la memoria caché L1/L2, mitigando el castigo de latencia y evitando el costoso viaje a la RAM.